Token Recognition and Analysis
Code Overview
This code performs lexical analysis on a given source code written in a custom programming language. It recognizes various types of tokens (e.g., keywords, identifiers, constants, operators) and stores information about them in two main data structures: the Symbol Table and the Formatted Instruction Program (FIP).

Tables Used
Symbol Table:
The symbol table is a data structure used to store unique tokens encountered in the source code.
Tokens in the symbol table are categorized into keywords, identifiers, constants, operators, and delimiters.
Each token is assigned a unique position/index in the symbol table.
Formatted Instruction Program (FIP):
The FIP is a data structure that pairs a code with the position of the corresponding token in the symbol table.
It serves as an intermediary data structure for identifying and categorizing tokens.
Tokens in the FIP are assigned specific codes to represent their category.

Token Categories and Codes
The code defines several regular expressions and assigns codes to tokens based on their categories. The codes are as follows:

FIP Code 0: Identifiers
Represents user-defined names (e.g., variable names, function names).
FIP Code 1: Constants
Represents numeric values (e.g., integers, floats).
FIP Code 2: Operators and Delimiters
Represents operators (e.g., +, -, *, /, ==, !=, <=, =, <, {, }, (, ), ;, ,) and delimiters.
FIP Code 3: Keywords
Represents reserved words in the programming language (e.g., is, show, isnot, while, read, sum, main, import).
FIP Code 4: String Literals
Represents text enclosed in double quotes.
Token Recognition
The code follows a scanning process to recognize tokens in the source code. It iterates through the source code character by character and uses regular expressions to match and categorize tokens. It checks whether a token is an identifier, constant, operator, delimiter, keyword, or string literal.

Error Handling
The code provides error handling for cases where tokens do not match the expected patterns. It reports errors for invalid tokens and their positions in the source code.

Code Execution
The source code is read from a file specified as "test.txt."

The code performs lexical analysis and token recognition.

The FIP and the symbol table are populated with token codes and positions.

The FIP and symbol table are written to separate output files: "output_fip.txt" and "output_symbol_table.txt."

The code reports any lexical errors it encounters.

The final output displays messages confirming the successful generation of the FIP and symbol table files.

Please note that the code snippet you provided at the end of the documentation does not seem to be part of the code documentation. If you have any specific questions or need further clarification, feel free to ask.




